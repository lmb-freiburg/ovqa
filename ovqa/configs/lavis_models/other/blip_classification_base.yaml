# Copyright (c) 2022, salesforce.com, inc.
# All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause
# For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

model:
    arch: blip_classification
    pretrained: "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_caption_capfilt_large.pth"

    use_distill: True
    momentum: 0.995
    alpha: 0.4
    num_classes: 2

    # vit encoder
    vit_type: "base"
    vit_grad_ckpt: False
    vit_ckpt_layer: 0

    image_size: 384

    # bert config
    med_config_path: "ovqa/configs/lavis_models/other/med_config.json"

# todo if you use this model, probably adjust the preprocessing
preprocess:
    vis_processor:
        train:
            name: "blip_image_train"
        eval:
            name: "blip_image_eval"
    text_processor:
        train:
            name: "blip_caption"
        eval:
            name: "blip_caption"
